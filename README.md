# WcGAN-GP-MNIST

[![Website](https://img.shields.io/badge/Site%20Pessoal-RGivisiez-red?style=flat&for-the-badge&logo=github)][mysite]

> The notebook is better visualized using Google Colab:
> 
>  <a href="https://colab.research.google.com/github/RGivisiez/WcGAN-GP-MNIST/blob/main/WcGAN_GP_(MNIST).ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

The main objective is to train a conditional GAN and use its generator to create images. Since GANs require a lot of computational resources, the dataset size and the number of classes used will be restricted. My main objective is to see the entire process of training a GAN.

To keep track of the training loss and the images generated, TensorBoard was used. Moreover, to prevent the well-known mode collapse, present in basic GAN implementations, I used the Wasserstein loss with a gradient penalty.

The images below show the results for two different models:

![0-2-model-1](img/model1.png)
|:--:| 
| *Images generated by a simpler model.* |

![0-2-model-2](img/model2.png)
|:--:| 
| *Images generated by a more powerfull model.* |

[mysite]: https://rgivisiez.github.io/
